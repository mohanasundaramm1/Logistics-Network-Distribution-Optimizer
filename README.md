# Logistics Network & Distribution Optimizer

An end-to-end analytics engine that operationalizes logistics network design by integrating validated ETL pipelines with Mixed-Integer Programming solvers to maximize distribution profitability.

## ðŸš€ Project Overview
This project transforms a standard mathematical optimization problem into a scalable microservice. It leverages **Mixed-Integer Programming (MIP)** via Gurobi to maximize daily operational profit by optimally placing vehicles and assigning customer demand nodes.

### Core Features
- **ETL Pipeline**: Automated ingestion from raw CSV files to a validated Relational Database (SQLite).
- **Data Integrity**: Multi-layered validation using **Pydantic** for schema enforcement and logic constraints.
- **Optimization Engine**: High-performance solver logic using **Gurobi 12.0**.
- **RESTful Interface**: A stateless API built with **FastAPI** to operationalize logistics decisions.

---

## ðŸ— System Architecture

The following diagram illustrates the data flow from raw source to actionable decision output.

```mermaid
graph TD
    A[Raw CSV Data] -->|ingest.py| B{Validation Layer}
    B -->|Passed| C[(SQLite Database)]
    B -->|Failed| D[Error Logs]
    C -->|Query| E[Optimization Model]
    E -->|Gurobi Solver| F[Optimal Fleet Logic]
    G[REST API Endpoint] -->|Trigger| E
    F -->|Result| G
    G -->|JSON Response| H[Operations Dashboard]
```

### Folder Structure
```text
supply_chain_optimization_repo/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Source CSV files
â”‚   â””â”€â”€ processed/       # SQLite production database
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py           # FastAPI application & routes
â”‚   â”œâ”€â”€ database.py      # SQLAlchemy models & DB connection
â”‚   â”œâ”€â”€ ingest.py        # ETL & Ingestion logic
â”‚   â”œâ”€â”€ models.py        # Pydantic schemas for validation
â”‚   â””â”€â”€ optimizer.py     # Gurobi mathematical formulation
â”œâ”€â”€ logs/                # Pipeline and application logs
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Technical documentation
```

---

## ðŸ›  Setup & Installation

### 1. Prerequisites
- Python 3.10+
- Gurobi License (Academic or Commercial)

### 2. Installation
```bash
# Clone the repository
git clone <repo-url>
cd supply_chain_optimization_repo

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows use venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Run Ingestion (ETL)
Populate the database from raw CSV files:
```bash
python3 -m src.ingest
```

### 4. Start the API
Launch the logistics optimization microservice:
```bash
uvicorn src.api:app --reload --port 8000
```

---

## ðŸ”Œ API Specification

### `POST /optimize`
Triggers the optimization engine based on current database state.

**Response Example:**
```json
{
  "status": "OPTIMAL",
  "optimal_profit": 3710.0,
  "chosen_trucks": ["truck8", "truck16", "truck26"],
  "assignments": {
    "truck8": ["demand0", "demand1", "demand2"]
  }
}
```

---

## ðŸŽ¯ Resume Alignment

This project specifically highlights these **Data Engineering** skills:
- **Data Pipeline Construction**: Moving data from Bronze (CSV) to Gold (SQL Relational) storage.
- **Microservices Implementation**: Wrapping complex algorithms in RESTful APIs.
- **Relational Data Modeling**: Designing optimized SQL schemas using SQLAlchemy.
- **Data Quality Control**: Implementing strict validation contracts via Pydantic.
